# -*- coding: utf-8 -*-
"""Tom.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1le4N1D3or-KJorGPJOgMssw9zs5TnkV2
"""

import pandas as pd

# Since the files are in the main directory, we just need the filenames
train_file = 'train.csv'
test_file = 'test.csv'

try:
    df_train = pd.read_csv(train_file)
    df_test = pd.read_csv(test_file)
    print("‚úÖ Files loaded successfully!")

    # Display the first 5 rows of the training data to verify
    print("\n--- Training Data ---")
    display(df_train.head())

except FileNotFoundError as e:
    print(f"‚ùå Error: Could not find the file. Make sure '{e.filename}' is uploaded.")

"""#TEXT ONLY MODEL


"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Set up the plots
plt.figure(figsize=(12, 5))

# 1. Plot the original price distribution
plt.subplot(1, 2, 1) # (1 row, 2 columns, 1st plot)
sns.histplot(df_train['price'], kde=True, bins=50)
plt.title('Original Price Distribution (Skewed)')

# 2. Apply log transform and create a new column
# We use np.log1p which calculates log(1 + x) for numerical stability
df_train['log_price'] = np.log1p(df_train['price'])

# 3. Plot the new log-transformed price distribution
plt.subplot(1, 2, 2) # (1 row, 2 columns, 2nd plot)
sns.histplot(df_train['log_price'], kde=True, bins=50)
plt.title('Log-Transformed Price Distribution (Normal)')

plt.tight_layout()
plt.show()

import re

def extract_ipq(text):
    """
    Extracts the Item Pack Quantity (IPQ) from a text string.
    Looks for patterns like 'Pack of 12', '15 Count', '(2 Pack)', etc.
    """
    # Convert text to string to avoid errors with non-string types
    text = str(text)

    # This regex pattern looks for a number following common pack-size keywords
    # It is case-insensitive (re.IGNORECASE)
    match = re.search(r'(?:pack of|set of|count|\()(\s*)(\d+)', text, re.IGNORECASE)

    if match:
        # If a pattern is found, return the number as an integer
        return int(match.group(2))
    else:
        # If no pack size is found, we assume it's a single item
        return 1

# Apply the function to create a new 'ipq' column in both dataframes
df_train['ipq'] = df_train['catalog_content'].apply(extract_ipq)
df_test['ipq'] = df_test['catalog_content'].apply(extract_ipq)

print("‚úÖ 'ipq' feature created successfully!")

# Let's check our work by viewing some examples
print("\n--- Examples of Extracted IPQ ---")
display(df_train[['catalog_content', 'ipq', 'price']].head(10))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from lightgbm import LGBMRegressor

# 1. Define which columns to use for features (X) and the target (y)
# Our features are the text content and the pack quantity.
features = ['catalog_content', 'ipq']
target = 'log_price'

X_train = df_train[features]
y_train = df_train[target]

# 2. Set up a preprocessor with ColumnTransformer
# This is a powerful tool to apply different steps to different columns.
preprocessor = ColumnTransformer(
    transformers=[
        # Transformer 1: Apply TF-IDF to the 'catalog_content' column
        ('tfidf', TfidfVectorizer(stop_words='english', max_features=20000), 'catalog_content'),

        # Transformer 2: The 'ipq' column is already a number, so we just 'passthrough'
        ('ipq', 'passthrough', ['ipq'])
    ],
    remainder='drop' # Drop any columns we didn't specify
)

# 3. Create the full pipeline
# This chains the preprocessing step with the modeling step.
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LGBMRegressor(random_state=42))
])

# 4. Train the entire pipeline on our training data!
print("üöÄ Training the baseline model...")
pipeline.fit(X_train, y_train)
print("‚úÖ Model training complete!")

import pandas as pd
import numpy as np

# 1. Select the features from the test data
X_test = df_test[features]

# 2. Use the trained pipeline to predict on the test set
print("üöÄ Making predictions on the test data...")
log_predictions = pipeline.predict(X_test)

# 3. CRITICAL: Convert predictions back from log scale!
# The model predicted log_price, so we use the inverse function np.expm1()
# This converts log(1+price) back to price.
predictions = np.expm1(log_predictions)

# 4. Enforce constraints: Ensure all predicted prices are positive
predictions[predictions < 0] = 0

# 5. Create the submission DataFrame in the required format
submission_df = pd.DataFrame({
    'sample_id': df_test['sample_id'],
    'price': predictions
})

# 6. Save the submission file to CSV
# index=False is crucial to prevent pandas from writing an extra column.
submission_df.to_csv('submission.csv', index=False)

print("\n‚úÖ Submission file 'submission.csv' created successfully!")
print("Here's a preview of your submission file:")
display(submission_df.head())

import numpy as np

def smape(y_true, y_pred):
    """
    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).

    Args:
        y_true (array-like): Array of true values.
        y_pred (array-like): Array of predicted values.

    Returns:
        float: The SMAPE score as a percentage.
    """
    # Ensure inputs are numpy arrays
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    # Calculate the numerator and denominator
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2

    # Calculate the element-wise ratio
    # Use np.where to handle the case where the denominator is zero
    # If both true and predicted are 0, the error is 0.
    ratio = np.where(denominator == 0, 0, numerator / denominator)

    # Return the average of the ratios as a percentage
    return np.mean(ratio) * 100

# --- Example Usage ---
actual_prices = [100, 50, 200, 0]
predicted_prices = [120, 45, 210, 5]

smape_score = smape(actual_prices, predicted_prices)
print(f"SMAPE Score: {smape_score:.2f}%")
# Expected output will be a combination of the errors for each prediction.
# For just the first pair (100, 120), the score is 18.18%

"""#ADDING IMAGE FEATURES"""

# 1. Ensure the download functions are defined in your notebook
# (This is the code from your utils.py)
import re
import os
import pandas as pd
import multiprocessing
from tqdm import tqdm
import numpy as np
from pathlib import Path
from functools import partial
import urllib.request

def download_image(image_link, savefolder):
    if isinstance(image_link, str):
        filename = Path(image_link).name
        image_save_path = os.path.join(savefolder, filename)
        if not os.path.exists(image_save_path):
            try:
                urllib.request.urlretrieve(image_link, image_save_path)
            except Exception as ex:
                pass
    return

def download_images(image_links, download_folder):
    if not os.path.exists(download_folder):
        os.makedirs(download_folder)

    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
        download_func = partial(download_image, savefolder=download_folder)
        list(tqdm(pool.imap(download_func, image_links), total=len(image_links)))

# 2. Specify where to save the images
download_folder = '/content/train_images/'

# 3. Get ALL image links from your DataFrame
# This is the line that has been changed.
image_links_to_download = df_train['image_link'].tolist()

# 4. Call the function to start downloading!
print(f"Downloading all {len(image_links_to_download)} training images...")
download_images(image_links=image_links_to_download, download_folder=download_folder)
print(f"‚úÖ All images have been downloaded to the '{download_folder}' folder.")

# Install the PyTorch Image Models library by Ross Wightman
!pip install timm -q

import torch
import timm
from PIL import Image
from torchvision import transforms
import os
from tqdm import tqdm

# Set up the device to use a GPU if available (highly recommended)
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# 1. Load a pre-trained EfficientNet model
# 'num_classes=0' removes the final classification layer, so the model outputs feature vectors (embeddings)
model_name = 'efficientnet_b0'
model = timm.create_model(model_name, pretrained=True, num_classes=0).to(device)
model.eval() # Set the model to evaluation mode

# 2. Get the model's specific input transformations
# Every pre-trained model needs the images to be in a specific format (size, color normalization, etc.)
# 'timm' makes this easy by providing the default configuration.
config = model.default_cfg
transform = transforms.Compose([
    transforms.Resize(config['input_size'][1:]),
    transforms.CenterCrop(config['input_size'][1:]),
    transforms.ToTensor(),
    transforms.Normalize(mean=config['mean'], std=config['std']),
])

print(f"\nModel '{model_name}' loaded successfully!")
print(f"Images will be resized to {config['input_size'][1:]}x{config['input_size'][1:]}")

def get_image_embedding(image_path, model, transform, device):
    """
    Takes an image path, processes it, and returns its feature vector (embedding).
    """
    try:
        # Load and transform the image
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0).to(device) # Add batch dimension and send to GPU

        # Get the embedding
        with torch.no_grad(): # We don't need to calculate gradients
            embedding = model(image_tensor)

        # Return the embedding as a flat numpy array
        return embedding.cpu().numpy().flatten()

    except Exception as e:
        # If an image is broken or missing, return an array of zeros
        # This prevents our whole process from crashing.
        print(f"Warning: Could not process {image_path}. Error: {e}")
        # We need to know the output size of our model to create the zero vector
        # For efficientnet_b0, it's 1280
        return np.zeros(1280)

import numpy as np
from tqdm import tqdm
import os

# --- Configuration ---
# Make sure this path points to where you downloaded your images.
IMAGE_FOLDER = '/content/train_images/'
# The number of images you downloaded (e.g., 500, or 75000 for the full set).
NUM_IMAGES = 75000
# The size of the embedding vector from your model (efficientnet_b0 is 1280).
EMBEDDING_SIZE = 1280

# --- Process ---
# We'll work with a slice of the dataframe matching the number of images downloaded.
df_sample = df_train.head(NUM_IMAGES)

# Create the full file path for each image.
df_sample['image_path'] = df_sample['image_link'].apply(
    lambda url: os.path.join(IMAGE_FOLDER, os.path.basename(str(url)))
)

print(f"üöÄ Starting feature extraction for {len(df_sample)} images...")
image_embeddings = []

# Loop through each image path with a progress bar.
for path in tqdm(df_sample['image_path']):
    if os.path.exists(path):
        embedding = get_image_embedding(path, model, transform, device)
        image_embeddings.append(embedding)
    else:
        # If an image failed to download, append a vector of zeros.
        image_embeddings.append(np.zeros(EMBEDDING_SIZE))

# Convert the list of embeddings into a single 2D NumPy array.
image_embeddings = np.array(image_embeddings)

# Save the embeddings to a file for easy loading later!
np.save('train_image_embeddings.npy', image_embeddings)

print("\n‚úÖ Image feature extraction complete!")
print(f"Embeddings shape: {image_embeddings.shape}")
print("The embeddings have been saved to 'train_image_embeddings.npy'")

"""#MULTIMODAL




"""

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack
from lightgbm import LGBMRegressor
import os
from tqdm import tqdm

# ==============================================================================
#  PHASE 1: TRAINING ON THE FULL 75K DATASET
# ==============================================================================

# 1. Load your full training image embeddings with the CORRECT filename
print("Loading full 75k image embeddings...")
# --- THIS LINE HAS BEEN CORRECTED ---
image_embeddings = np.load('train_image_embeddings.npy')
print(f"Embeddings loaded successfully with shape: {image_embeddings.shape}")

# 2. Process text and IPQ features for the full dataset
print("Processing text and IPQ features...")
tfidf = TfidfVectorizer(stop_words='english', max_features=20000)
text_features = tfidf.fit_transform(df_train['catalog_content'])
ipq_features = df_train[['ipq']].values

# 3. Combine ALL features into the final training matrix
print("Combining all features for training...")
X_full_train = hstack([text_features, ipq_features, image_embeddings])
y_full_train = df_train['log_price']
print(f"Final training matrix created with shape: {X_full_train.shape}")

# 4. Define and train the powerful new model
full_model = LGBMRegressor(random_state=42, n_estimators=300, learning_rate=0.05)

print("\nüöÄ Training the FULL multi-modal model... (This may take a few minutes)")
full_model.fit(X_full_train, y_full_train)
print("‚úÖ Full multi-modal model is trained and ready!")

# ==============================================================================
#  PHASE 2: PROCESSING THE TEST SET AND SUBMITTING
# ==============================================================================

# 1. Process Test Images (Download and Feature Extraction)
print("\n--- Processing the Full Test Set ---")
test_image_folder = '/content/test_images/'
test_image_links = df_test['image_link'].tolist()

print(f"\nDownloading all {len(test_image_links)} test images... (This will take a few hours)")
download_images(image_links=test_image_links, download_folder=test_image_folder)

print(f"\nGenerating embeddings for all {len(df_test)} test images... (This will take 1-2 hours)")
df_test['image_path'] = df_test['image_link'].apply(
    lambda url: os.path.join(test_image_folder, os.path.basename(str(url)))
)

test_image_embeddings = []
for path in tqdm(df_test['image_path']):
    embedding = get_image_embedding(path, model, transform, device)
    test_image_embeddings.append(embedding)

test_image_embeddings = np.array(test_image_embeddings)
print("‚úÖ Test image processing complete.")

# 2. Combine all features for the test set
print("\nCombining all features for the test set...")
test_text_features = tfidf.transform(df_test['catalog_content'])
test_ipq_features = df_test[['ipq']].values
X_full_test = hstack([text_text_features, test_ipq_features, test_image_embeddings])

# 3. Generate the final submission file
print("\nüöÄ Making final predictions...")
predictions_log = full_model.predict(X_full_test)
final_predictions = np.expm1(predictions_log)
final_predictions[final_predictions < 0] = 0

submission_df = pd.DataFrame({
    'sample_id': df_test['sample_id'],
    'price': final_predictions
})
submission_df.to_csv('submission_multimodal_FULL.csv', index=False)

print("\nüéâ Success! New submission file 'submission_multimodal_FULL.csv' created.")
display(submission_df.head())

# All the necessary objects are already in memory. We just need to re-run the final steps.

# 1. Combine all features for the test set (with the corrected variable name)
print("Combining all features for the test set...")

# --- THIS IS THE CORRECTED LINE ---
# Use 'test_text_features' instead of 'text_text_features'
X_full_test = hstack([test_text_features, test_ipq_features, test_image_embeddings])
print("‚úÖ Features combined successfully.")

# 2. Generate the final submission file
print("\nüöÄ Making final predictions...")
predictions_log = full_model.predict(X_full_test)
final_predictions = np.expm1(predictions_log)
final_predictions[final_predictions < 0] = 0

submission_df = pd.DataFrame({
    'sample_id': df_test['sample_id'],
    'price': final_predictions
})
submission_df.to_csv('submission_multimodal_FULL.csv', index=False)

print("\nüéâ Success! New submission file 'submission_multimodal_FULL.csv' created.")
display(submission_df.head())

from sklearn.model_selection import train_test_split
from scipy.sparse import hstack
import numpy as np

# --- 1. Split your full 75k dataset into training (80%) and validation (20%) sets ---
# We split the indices to easily select corresponding image embeddings later.
train_indices, val_indices = train_test_split(df_train.index, test_size=0.2, random_state=42)

# --- 2. Prepare the features for the TRAINING split ---
# Use .loc to select the correct rows from the dataframe
df_train_split = df_train.loc[train_indices]

# Re-fit the TF-IDF vectorizer ONLY on the new, smaller training data
tfidf_val = TfidfVectorizer(stop_words='english', max_features=20000)
train_text_features = tfidf_val.fit_transform(df_train_split['catalog_content'])
train_ipq = df_train_split[['ipq']].values
# Select the corresponding image embeddings using the indices
train_img = image_embeddings[train_indices]

X_train_split = hstack([train_text_features, train_ipq, train_img])
y_train_split = df_train_split['log_price']

# --- 3. Prepare features for the VALIDATION split ---
df_val_split = df_train.loc[val_indices]

# IMPORTANT: Use .transform() on the validation text data
val_text_features = tfidf_val.transform(df_val_split['catalog_content'])
val_ipq = df_val_split[['ipq']].values
val_img = image_embeddings[val_indices]

X_val_split = hstack([val_text_features, val_ipq, val_img])
y_val_true_log = df_val_split['log_price']

# --- 4. Train a new model on the 80% training split ---
print("üöÄ Training a new model on the 80% data split for validation...")
validation_model = LGBMRegressor(random_state=42, n_estimators=300, learning_rate=0.05)
validation_model.fit(X_train_split, y_train_split)
print("‚úÖ Validation model training complete.")

# --- 5. Make predictions and calculate the SMAPE score ---
print("\nüîç Making predictions on the 20% validation set...")
val_log_predictions = validation_model.predict(X_val_split)

# Convert both true values and predictions back from log scale to the original price
y_val_true_price = np.expm1(y_val_true_log)
val_predicted_price = np.expm1(val_log_predictions)

# Use the SMAPE function
validation_smape = smape(y_val_true_price, val_predicted_price)

print(f"\n-------------------------------------------------")
print(f"üìä Your Estimated Local SMAPE Score: {validation_smape:.2f}%")
print(f"-------------------------------------------------")

import zipfile
import os

print("Creating the submission zip file...")

# Define the name of your final zip file
zip_filename = 'submission_package.zip'

# List the essential files you need to include in your submission
files_to_zip = [
    'submission_multimodal_FULL.csv', # Your latest prediction file
    'Tom.ipynb',                      # Your Colab notebook with all the code
    'Documentation.md'                # Your documentation file (make sure you've created this)
]

with zipfile.ZipFile(zip_filename, 'w') as zipf:
    for file in files_to_zip:
        if os.path.exists(file):
            zipf.write(file)
            print(f"  - Added '{file}' to the zip.")
        else:
            print(f"  - WARNING: Could not find '{file}'. It will be skipped.")

print(f"\n‚úÖ Successfully created '{zip_filename}'.")

# 1. Install the library
!pip install sentence-transformers -q

from sentence_transformers import SentenceTransformer

# 2. Load the advanced text model
print("Loading Sentence Transformer model...")
text_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)

# 3. Generate the advanced text embeddings for the TRAINING SET
print("\nGenerating advanced text embeddings for all 75k training samples...")
print("(This will take about 20-30 minutes)")
advanced_text_features = text_model.encode(df_train['catalog_content'].tolist(), show_progress_bar=True)

# 4. Save these new features to a file!
np.save('advanced_text_embeddings_TRAIN.npy', advanced_text_features)

print(f"\n‚úÖ Advanced text embeddings for the training set are created and saved!")

import pandas as pd
import numpy as np
from lightgbm import LGBMRegressor
import re

# --- 1. Define Helper Function ---
# THIS IS THE FIX: We define the function here so the script knows what it is.
def extract_ipq(text):
    text = str(text)
    match = re.search(r'(?:pack of|set of|count|\()(\s*)(\d+)', text, re.IGNORECASE)
    if match:
        return int(match.group(2))
    return 1
# --- END OF FIX ---

# --- 2. Load Data and Perform Basic Feature Engineering ---
print("Loading data and preparing base features...")
df_train = pd.read_csv('train.csv')
df_train['ipq'] = df_train['catalog_content'].apply(extract_ipq)
df_train['log_price'] = np.log1p(df_train['price'])

# --- 3. Load Your Pre-Computed Embeddings ---
print("Loading all advanced features for training...")
advanced_text_features = np.load('advanced_text_embeddings_TRAIN.npy')
image_embeddings = np.load('train_image_embeddings.npy')
ipq_features = df_train[['ipq']].values

# --- 4. Combine All Features ---
print("Combining ADVANCED text, IPQ, and image features...")
X_advanced_train = np.hstack([advanced_text_features, ipq_features, image_embeddings])
y_full_train = df_train['log_price']

# --- 5. Define and Train Your Final Model ---
advanced_model = LGBMRegressor(random_state=42, n_estimators=500, learning_rate=0.05)

print("\nüöÄ Training the final, advanced multi-modal model...")
advanced_model.fit(X_advanced_train, y_full_train)
print("üèÜ Final model is trained and ready!")

"""#FINAL CODE

"""

# ==============================================================================

# ==============================================================================
import pandas as pd
import numpy as np
import re
import os
from tqdm import tqdm
import zipfile

import torch
import timm
from PIL import Image
from torchvision import transforms
from sentence_transformers import SentenceTransformer
from lightgbm import LGBMRegressor
import urllib.request
from pathlib import Path

# --- 1. SETUP AND HELPER FUNCTIONS ---
print("--- STEP 1/5: INITIALIZING SETUP ---")

def extract_ipq(text):
    text = str(text)
    match = re.search(r'(?:pack of|set of|count|\()(\s*)(\d+)', text, re.IGNORECASE)
    if match:
        return int(match.group(2))
    return 1

def download_images(image_links, download_folder):
    os.makedirs(download_folder, exist_ok=True)
    for link in tqdm(image_links, desc=f"Downloading to {download_folder}"):
        if isinstance(link, str):
            fpath = os.path.join(download_folder, Path(link).name)
            if not os.path.exists(fpath):
                try: urllib.request.urlretrieve(link, fpath)
                except Exception: pass

def get_image_embedding(image_path, model, transform, device):
    try:
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0).to(device)
        with torch.no_grad():
            embedding = model(image_tensor)
        return embedding.cpu().numpy().flatten()
    except Exception:
        return np.zeros(1280)

# Setup device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")
if device == "cpu":
    print("üî¥ WARNING: YOU ARE ON A CPU. THIS WILL BE EXTREMELY SLOW. SWITCH TO A GPU RUNTIME.")

# Load models
image_model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0).to(device)
image_model.eval()
config = image_model.default_cfg
image_transform = transforms.Compose([
    transforms.Resize(config['input_size'][1:]),
    transforms.CenterCrop(config['input_size'][1:]),
    transforms.ToTensor(),
    transforms.Normalize(mean=config['mean'], std=config['std']),
])
text_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)

# --- 2. RE-GENERATE ALL TRAINING FEATURES ---
print("\n--- STEP 2/5: RE-GENERATING ALL TRAINING FEATURES ---")
df_train = pd.read_csv('train.csv')
df_train['ipq'] = df_train['catalog_content'].apply(extract_ipq)
df_train['log_price'] = np.log1p(df_train['price'])
ipq_features = df_train[['ipq']].values

# Re-create image embeddings for training
train_image_folder = 'train_images/'
download_images(df_train['image_link'].tolist(), train_image_folder)
train_image_embeddings = []
df_train['image_path'] = df_train['image_link'].apply(lambda url: os.path.join(train_image_folder, os.path.basename(str(url))))
for path in tqdm(df_train['image_path'], desc="Generating train image embeddings"):
    train_image_embeddings.append(get_image_embedding(path, image_model, image_transform, device))
train_image_embeddings = np.array(train_image_embeddings)

# Re-create text embeddings for training
advanced_text_features = text_model.encode(df_train['catalog_content'].tolist(), show_progress_bar=True)

# --- 3. RE-TRAIN THE FINAL MODEL ---
print("\n--- STEP 3/5: RE-TRAINING THE FINAL MODEL ---")
X_advanced_train = np.hstack([advanced_text_features, ipq_features, train_image_embeddings])
y_full_train = df_train['log_price']
advanced_model = LGBMRegressor(random_state=42, n_estimators=500, learning_rate=0.05)
advanced_model.fit(X_advanced_train, y_full_train)
print("üèÜ Final model is trained and ready!")

# --- 4. RE-GENERATE ALL TEST FEATURES ---
print("\n--- STEP 4/5: RE-GENERATING ALL TEST FEATURES ---")
df_test = pd.read_csv('test.csv')
df_test['ipq'] = df_test['catalog_content'].apply(extract_ipq)
test_ipq_features = df_test[['ipq']].values

# Re-create image embeddings for testing
test_image_folder = 'test_images/'
download_images(df_test['image_link'].tolist(), test_image_folder)
test_image_embeddings = []
df_test['image_path'] = df_test['image_link'].apply(lambda url: os.path.join(test_image_folder, os.path.basename(str(url))))
for path in tqdm(df_test['image_path'], desc="Generating test image embeddings"):
    test_image_embeddings.append(get_image_embedding(path, image_model, image_transform, device))
test_image_embeddings = np.array(test_image_embeddings)

# Re-create text embeddings for testing
advanced_text_features_test = text_model.encode(df_test['catalog_content'].tolist(), show_progress_bar=True)

# --- 5. MAKE FINAL PREDICTION AND SAVE ---
print("\n--- STEP 5/5: MAKING FINAL PREDICTIONS ---")
X_advanced_test = np.hstack([advanced_text_features_test, test_ipq_features, test_image_embeddings])
adv_predictions_log = advanced_model.predict(X_advanced_test)
adv_final_predictions = np.expm1(adv_predictions_log)
adv_final_predictions[adv_final_predictions < 0] = 0

# Create and save the final submission file
submission_df_final = pd.DataFrame({
    'sample_id': df_test['sample_id'],
    'price': adv_final_predictions
})

# --- THIS IS THE CORRECTED FILENAME ---
output_filename = 'test_out.csv'
submission_df_final.to_csv(output_filename, index=False)
print(f"\nüéâ Success! Your final submission file '{output_filename}' is ready.")
display(submission_df_final.head())

# 1. Install the library
!pip install sentence-transformers -q

from sentence_transformers import SentenceTransformer
import torch

# 2. Setup device and load the advanced text model
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")
text_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)

# 3. Generate the advanced text embeddings for the TRAINING SET
print("\nGenerating advanced text embeddings for all 75k training samples...")
advanced_text_features = text_model.encode(df_train['catalog_content'].tolist(), show_progress_bar=True)

# 4. Save these features to a file for safety
np.save('advanced_text_embeddings_TRAIN.npy', advanced_text_features)
print(f"\n‚úÖ Advanced text embeddings for the training set are created and saved!")